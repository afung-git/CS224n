{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initialized_Conv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,\n",
    "                 kernel_size=1, stride=1, padding=0, groups=1,\n",
    "                 relu=False, bias=False):\n",
    "        super().__init__()\n",
    "        self.out = nn.Conv1d(\n",
    "            in_channels, out_channels,\n",
    "            kernel_size, stride=stride,\n",
    "            padding=padding, groups=groups, bias=bias)\n",
    "        nn.init.constant_(self.out.weight, 1.)\n",
    "        if relu is True:\n",
    "            self.relu = True\n",
    "#             nn.init.kaiming_normal_(self.out.weight, nonlinearity='relu')\n",
    "        else:\n",
    "            self.relu = False\n",
    "#             nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.relu is True:\n",
    "            return F.relu(self.out(x))\n",
    "        else:\n",
    "            return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_logits(target, mask):\n",
    "    mask = mask.type(torch.float32)\n",
    "    return target * mask + (1 - mask) * (-1e30)  # !!!!!!!!!!!!!!!  do we need * mask after target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.dropout = dropout\n",
    "        self.mem_conv = Initialized_Conv1d(in_channels=d_model, out_channels=d_model*2, kernel_size=1, relu=False, bias=False)\n",
    "        self.query_conv = Initialized_Conv1d(in_channels=d_model, out_channels=d_model, kernel_size=1, relu=False, bias=False)\n",
    "\n",
    "        bias = torch.empty(1)\n",
    "        nn.init.constant_(bias, 0)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "    def forward(self, queries, mask):\n",
    "        \"\"\"\n",
    "        queries: B x D x L\n",
    "        \"\"\"\n",
    "        memory = queries\n",
    "\n",
    "        memory = self.mem_conv(memory)  # B x 2D x L\n",
    "        query = self.query_conv(queries)  # B x D x L\n",
    "        memory = memory.transpose(1, 2)  # B x L x 2D\n",
    "        query = query.transpose(1, 2)  # B x L x D\n",
    "        Q = self.split_last_dim(query, self.num_head)  # B x L x H//D x H\n",
    "        K, V = [self.split_last_dim(tensor, self.num_head) for tensor in torch.split(memory, self.d_model, dim=2)]\n",
    "        # split memory into 2 (B x L x D). Key & value then split into\n",
    "        key_depth_per_head = self.d_model // self.num_head\n",
    "\n",
    "        Q *= key_depth_per_head**-0.5\n",
    "        x = self.dot_product_attention(Q, K, V, mask = mask)\n",
    "        return self.combine_last_two_dim(x.permute(0,2,1,3)).transpose(1, 2)\n",
    "\n",
    "    def dot_product_attention(self, q, k ,v, bias = False, mask = None):\n",
    "        \"\"\"dot-product attention.\n",
    "        Args:\n",
    "        q: a Tensor with shape [batch, heads, length_q, depth_k]\n",
    "        k: a Tensor with shape [batch, heads, length_kv, depth_k]\n",
    "        v: a Tensor with shape [batch, heads, length_kv, depth_v]\n",
    "        bias: bias Tensor (see attention_bias())\n",
    "        is_training: a bool of training\n",
    "        scope: an optional string\n",
    "        Returns:\n",
    "        A Tensor.\n",
    "        \"\"\"\n",
    "        logits = torch.matmul(q,k.permute(0,1,3,2))\n",
    "        print(logits)\n",
    "        if bias:\n",
    "            logits += self.bias\n",
    "        if mask is not None:\n",
    "            shapes = [x  if x != None else -1 for x in list(logits.size())]\n",
    "            mask = mask.view(shapes[0], 1, 1, shapes[-1])\n",
    "            logits = mask_logits(logits, mask)\n",
    "\n",
    "        weights = F.softmax(logits, dim=-1)\n",
    "        # dropping out the attention links for each of the heads\n",
    "        weights = F.dropout(weights, p=self.dropout, training=self.training)\n",
    "        return torch.matmul(weights, v)\n",
    "\n",
    "    def split_last_dim(self, x, n):\n",
    "        \"\"\"Reshape x so that the last dimension becomes two dimensions.\n",
    "        The first of these two dimensions is n.\n",
    "        Args:\n",
    "        x: a Tensor with shape [..., m]\n",
    "        n: an integer.\n",
    "        Returns:\n",
    "        a Tensor with shape [..., n, m/n]\n",
    "        \"\"\"\n",
    "        old_shape = list(x.size())  # B x L x D\n",
    "        last = old_shape[-1]  # D\n",
    "        new_shape = old_shape[:-1] + [n] + [last // n if last else None] # (B x L) x H x D//H\n",
    "        ret = x.view(new_shape) # B x L x H x D//n\n",
    "        return ret.permute(0, 2, 1, 3)  # B x H x L x D//n\n",
    "\n",
    "    def combine_last_two_dim(self, x):\n",
    "        \"\"\"Reshape x so that the last two dimension become one.\n",
    "        Args:\n",
    "        x: a Tensor with shape [..., a, b]\n",
    "        Returns:\n",
    "        a Tensor with shape [..., ab]\n",
    "        \"\"\"\n",
    "        old_shape = list(x.size())\n",
    "        a, b = old_shape[-2:]\n",
    "        new_shape = old_shape[:-2] + [a * b if a and b else None]\n",
    "        ret = x.contiguous().view(new_shape)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(masks, decode=False):\n",
    "    \"\"\"\n",
    "    :param masks: 0 for pad, 1 for non-pad (batch x seq_len)\n",
    "    :param decode: decoders are Auto-Regressive (can't see future words)\n",
    "    :return: mask: (batch x seq_len x seq_len / batch x 1 x seq_len)\n",
    "    \"\"\"\n",
    "    masks = masks.unsqueeze(-2)  # Pad words should not be zeroed across their whole rows\n",
    "    if decode:\n",
    "        masks = masks & torch.from_numpy(np.tril(np.ones(masks.shape[-1]))).byte()\n",
    "    return masks.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(query, key, value, mask=None, dp=None):\n",
    "    \"\"\"\n",
    "    :param query: Query tensor (batch x heads x seq_len x d_k)\n",
    "    :param key: Key tensor (batch x heads x seq_len x d_k)\n",
    "    :param value: Value tensor (batch x heads x seq_len x d_k)\n",
    "    :param mask: Optional mask, same for all heads (batch x heads x seq_len x seq_len)\n",
    "    :param dp: Dropout layer\n",
    "    :return: output, scores (batch x heads x seq_len x d_k), (batch x heads x seq_len x seq_len)\n",
    "    \"\"\"\n",
    "    logits = torch.matmul(query/(key.shape[-1]**(.5)), key.transpose(-1, -2))\n",
    "    print(logits)\n",
    "    if mask is not None:\n",
    "        logits = logits.masked_fill(mask == 0, -1e9)  # NOT 1e-9. Softmax(1e-9) is still 1.\n",
    "\n",
    "    scores = F.softmax(logits, dim=-1)\n",
    "    if dp is not None:\n",
    "        scores = dp(scores)\n",
    "    return torch.matmul(scores, value), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, heads, hidden_size, drop_prob=0.):\n",
    "        \"\"\"\n",
    "        :param heads: Number of attention heads to use\n",
    "        :param hidden_size: Dimension of input/output vectors\n",
    "        :param drop_prob: Dropout rate\n",
    "        \"\"\"\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "\n",
    "        assert hidden_size % heads == 0, \"hidden_size not a multiple of heads\"\n",
    "\n",
    "        self.d_k = hidden_size // heads\n",
    "        self.heads = heads\n",
    "        self.Linears = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias=False) for _ in range(3)])\n",
    "        for Lin in self.Linears:\n",
    "            nn.init.constant_(Lin.weight, 1.)\n",
    "\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        :param q: Query tensor (batch_size x seq_len x hidden_size)\n",
    "        :param k: Key tensor (batch_size x seq_len x hidden_size)\n",
    "        :param v: Value tensor (batch_size x seq_len x hidden_size)\n",
    "        :param mask: Optional mask (batch_size x seq_len x seq_len)\n",
    "        :return: o: output tensor (batch_size x seq_len x hidden_size)\n",
    "        \"\"\"\n",
    "        batch_size = q.shape[0]\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)  # (batch_size x 1 x seq_len x seq_len)\n",
    "        \n",
    "        # Get the Q, K, V in multiple-heads form after linear layers\n",
    "        q, k, v = [l(x).view(batch_size, -1, self.heads, self.d_k).transpose(1, 2)\n",
    "                   for l, x in zip(self.Linears, (q, k, v))]\n",
    "\n",
    "        o, self.attn = self_attention(q, k, v, mask, self.dropout)  # (batch_size, heads, seq_len, d_k)\n",
    "        \n",
    "        o = o.transpose(1, 2).contiguous().view(batch_size, -1, self.heads*self.d_k)\n",
    "\n",
    "        #return self.Linears[-1](o)  # Some dont use this.\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA = SelfAttention(6, 2, 0.)  # Depth, Heads\n",
    "MHSA = MultiHeadSelfAttention(2, 6, 0.)  # Heads, Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.ones((3,4,6))  # B x L x D\n",
    "M = torch.cat((torch.ones((3,2)), torch.zeros(3,2)), dim=1)  # B x L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]],\n",
      "\n",
      "         [[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]]],\n",
      "\n",
      "\n",
      "        [[[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]],\n",
      "\n",
      "         [[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]]],\n",
      "\n",
      "\n",
      "        [[[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]],\n",
      "\n",
      "         [[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.]],\n",
       "\n",
       "        [[6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.]],\n",
       "\n",
       "        [[6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA(Q.transpose(1, 2),M).transpose(1, 2)  # B x L x D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]],\n",
      "\n",
      "         [[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]]],\n",
      "\n",
      "\n",
      "        [[[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]],\n",
      "\n",
      "         [[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]]],\n",
      "\n",
      "\n",
      "        [[[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]],\n",
      "\n",
      "         [[62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538],\n",
      "          [62.3538, 62.3538, 62.3538, 62.3538]]]],\n",
      "       grad_fn=<UnsafeViewBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.]],\n",
       "\n",
       "        [[6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.]],\n",
       "\n",
       "        [[6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.],\n",
       "         [6., 6., 6., 6., 6., 6.]]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHSA(Q, Q, Q, make_mask(M))  # B x L x D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA(Q.transpose(1, 2),M).transpose(1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 6])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHSA(Q, Q, Q, make_mask(M)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
